---
title: "visualization"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(SPM)
library(e1071)
```

Let's stick to the idea of rotate one class-specific topic. The only things that should be changed are the topics.

#### functions

```{r}
vis_rotate <- function(r, Ntheta, s, N){
  k0 <- 1
  k1 <- 1
  nlabel <- 13 # one fixed
  d <- 2
  seed <- 1
  rho <- c(0.5, 0.5)
  a <- 10

  S <- matrix(
    rep(1, 2 * (1 + nlabel)),
    ncol = d,
    byrow = TRUE
  )
  S <- S * s
  
  dg <- k0 + k1
  K <- nlabel * k0 + k1
  ntopic <- K
  
  Ts <- T_generator(k0, k1, nlabel)
  
  thetas <- pi * seq(0, 1, length.out = Ntheta + 1) 
  Mu <- matrix( 
    c(r * cos(thetas), 0, r * sin(thetas), 0),
    ncol = d,
    byrow = FALSE)
  
  Lambda <- 1 / S
  Tau <- Mu * Lambda
  
  # genarate data
  set.seed(seed)
  
  #G <- gtools::rdirichlet(n = N, alpha = a * rho)
  
  dat <- document_generator_Normal(a, rho, Ts, Lambda, Tau, N, NULL, seed)
  
  plot_dat <- data.frame(dat$X, factor(dat$Y))
  names(plot_dat) <- c("X1", "X2", "Y")
  
  
  p <- plot_dat %>% ggplot(aes(x = X1, y = X2, color = Y)) +
    geom_point()
  print(p)
  
  dat
}

# the function to generate the dataset
training_dat_generator <- function(r, theta, s, N = 100, seed = NULL){
  k0 <- 1
  k1 <- 1
  nlabel <- 2
  d <- 2
  rho <- c(0.5, 0.5)
  
  a <- 10

  S <- matrix(
    c(1, 1, 1, 1, 1, 1),
    ncol = d,
    byrow = TRUE
  )
  S <- S * s
  
  dg <- k0 + k1
  K <- nlabel * k0 + k1
  ntopic <- K
  
  Ts <- T_generator(k0, k1, nlabel)
  
  Mu <- matrix( 
    c(1, 0, r * cos(theta), r * sin(theta), 0, 0),
    ncol = d,
    byrow = TRUE
  )
  
  Lambda <- 1 / S
  Tau <- Mu * Lambda
  
  dat <- document_generator_Normal(a, rho, Ts, Lambda, Tau, N, NULL, seed)
  list(X = dat$X, Y = dat$Y, U = dat$U, G = dat$G, Mu = Mu, S = S, Lambda = Lambda, Tau = Tau)
}

vis_2d <- function(X, Y){
  tem <- data.frame(X, Y)
  colnames(tem) <- c("X1", "X2", "Y")
  p <- tem %>% ggplot(aes(x = X1, y = X2, color = Y)) + geom_point()
  p
}
```

#### visualization

```{r}
dat <- vis_rotate(1, 12, 0.1, 1300 * 2)
dat <- vis_rotate(1, 12, 0.01, 1300 * 2)
dat <- vis_rotate(1, 12, 0.001, 1300 * 2)
dat <- vis_rotate(1, 12, 0.0001, 1300 * 2)
```

#### Compare predictive power under different settings
```{r}
theta <- pi / 2
seed1 <- 1
seed2 <- 2

mu_Mu <- 0
alpha_Lambda <- 1


Ts <- T_generator(1, 1, 2)
```

```{r}
s <- 0.001

sigma2_Mu <- 1 / s
beta_Lambda <- 1 / s


dat <- training_dat_generator(r = 1, theta = theta, s = s, N = 100, seed = seed1) # for training
dat2 <- training_dat_generator(r = 1, theta = theta, s = s, N = 100, seed = seed2) # for testing

```

##### SPM
```{r}
#SPM
res_VI <- SPM_training_Normal(X = dat[["X"]], Y = dat[["Y"]], Ts = Ts, b = 0.1, alpha = c(1, 1), mu_Mu = mu_Mu, sigma2_Mu = sigma2_Mu, alpha_Lambda = alpha_Lambda, beta_Lambda = beta_Lambda, VI = TRUE, nskip = 2, seed = 1)
```
```{r}
res_VI[["Mu"]]
plot(res_VI[["Mu"]][,1], res_VI[["Mu"]][,2])
```

```{r}
# compare membership
corrplot::corrplot(cor(t(dat[["U"]])))
corrplot::corrplot(cor(t(U(res_VI[["G"]], dat[["Y"]], Ts))))
```

```{r}
### test accuracy
prediction_VI <- SPM_predicting_Normal(X = dat2[["X"]], Lambda = res_VI[["Lambda"]], Mu = res_VI[["Mu"]], a = res_VI[["a"]], rho = res_VI[["rho"]], Ts = Ts, nsample = nsample, seed = 1, w = NULL)
sum(prediction_VI[["labels"]] == dat2[["Y"]]) # 100
```

```{r}
para1 <- get_parameters_Normal(X = dat[["X"]], Lambda = dat[["Lambda"]], Mu = dat[["Mu"]], U = dat[["U"]])
para2 <- get_parameters_Normal(X = dat[["X"]], Lambda = res_VI[["Lambda"]], Mu = res_VI[["Mu"]], G = res_VI[["G"]], Y = dat[["Y"]], Ts = Ts)
cbind(para1[["MuX"]], para2[["MuX"]])
para1[["MuX"]] - para2[["MuX"]]
```


##### BPM
```{r}
# training with NUTS
start_time <- Sys.time()
res_NUTS_BPM <- BPM_training_Normal(X = dat[["X"]], b = b, alpha = rep(1, ntopic), mu_Mu = mu_Mu, sigma2_Mu = sigma2_Mu, alpha_Lambda = alpha_Lambda, beta_Lambda = beta_Lambda, ntopic = ntopic, VI = FALSE, ntrace = 1000, nchain = 1, nskip = 2, seed = 1)
end_time <- Sys.time()
end_time - start_time # 6.018202 mins
```
```{r}
res_NUTS_BPM2 <- BPM_training_Normal(X = dat[["X"]], b = b, alpha = rep(1, ntopic), mu_Mu = mu_Mu, sigma2_Mu = 1, alpha_Lambda = alpha_Lambda, beta_Lambda = 0.1, ntopic = ntopic, VI = FALSE, ntrace = 1000, nchain = 1, nskip = 2, seed = 1)
bac <- res_NUTS_BPM
bac1 <- res_NUTS_BPM
res_NUTS_BPM <- res_NUTS_BPM2
```

```{r}
# check estimated memberships
corrplot::corrplot(cor(t(dat[["U"]])))
corrplot::corrplot(cor(t(res_NUTS_BPM[["U"]])))
# overall, it's very similar
```

```{r}
# check estimated membership
res_NUTS_BPM[["rho"]] # 0.2088413 0.2472414 0.2968298 0.2470875
res_NUTS_BPM[["a"]] # 0.4785404
sum((res_NUTS_BPM[["U"]]) > 0.8) / N # 0.71 tends to attribute the data point to a dominant class
sum(gtools::rdirichlet(n = 50, alpha = res_NUTS_BPM[["a"]] * res_NUTS_BPM[["rho"]]) > 0.8) / 50 # 0.54
```

```{r}
# test accuracy
svm_NUTS <- svm(factor(dat[["Y"]]) ~ res_NUTS_BPM[["U"]]) # train SVM

prediction_NUTS_BPM <- predict(svm_NUTS, res_NUTS_BPM[["U"]])
sum(prediction_NUTS_BPM == factor(dat[["Y"]])) # 61
```


```{r}
# compare estimate of distribution for training set
para1 <- get_parameters_Normal(X = dat[["X"]], Lambda = dat[["Lambda"]], Mu = dat[["Mu"]], U = dat[["U"]])
para2 <- get_parameters_Normal(X = dat[["X"]], Lambda = res_NUTS_BPM[["Lambda"]], Mu = res_NUTS_BPM[["Mu"]], U = res_NUTS_BPM[["U"]])
para1[["MuX"]] - para2[["MuX"]]
(para1[["MuX"]])[1:5, 1:5]
(para1[["SigmaX"]])[1:5, 1:5]
(para2[["SigmaX"]])[1:5, 1:5]
(para1[["MuX"]] - para2[["MuX"]])[1:5, 1:5] # seems even closer than SPM
sum(abs(para1[["MuX"]] - para2[["MuX"]]) / sqrt(para2[["SigmaX"]]) > 3) / N / d # 0
```

```{r}
# estimate memberships
U_NUTS <- BPM_membership_Normal(X = dat2[["X"]], Lambda = res_NUTS_BPM[["Lambda"]], Mu = res_NUTS_BPM[["Mu"]], a = res_NUTS_BPM[["a"]], rho = res_NUTS_BPM[["rho"]], VI = FALSE, nchain = 1, nskip = 2, seed = 1)
```

```{r}
# test accuracy
svm_NUTS <- svm(factor(dat[["Y"]]) ~ res_NUTS_BPM[["U"]]) # train SVM

prediction_NUTS_BPM <- predict(svm_NUTS, res_NUTS_BPM[["U"]])
sum(prediction_NUTS_BPM == factor(dat[["Y"]])) # 100

prediction_NUTS_BPM <- predict(svm_NUTS, U_NUTS)
sum(prediction_NUTS_BPM == factor(dat2[["Y"]])) # 100
```




```{r}
save.image("power_curve.Rdata")
```

#### curve
```{r}
estimate_BPM <- list()
accuracy_BPM <- c() # 65 63 71 99 100 100 100 100 100 100 100 100
for (i in 2:12){
  print(i)
  theta <- pi / 12 * i
  s <- 0.01

  dat <- training_dat_generator(r = 1, theta = theta, s = s, N = 100, seed = seed1) # for training
  dat2 <- training_dat_generator(r = 1, theta = theta, s = s, N = 100, seed = seed2) # for testing
  
  res_NUTS_BPM <- BPM_training_Normal(X = dat[["X"]], b = b, alpha = rep(1, ntopic), mu_Mu = mu_Mu, sigma2_Mu = 1, alpha_Lambda = alpha_Lambda, beta_Lambda = 0.1, ntopic = ntopic, VI = FALSE, ntrace = 1000, nchain = 1, nskip = 2, seed = 1)
  svm_NUTS <- svm(factor(dat[["Y"]]) ~ res_NUTS_BPM[["U"]]) # train SVM
  
  prediction_NUTS_BPM <- predict(svm_NUTS, res_NUTS_BPM[["U"]])
  print(sum(prediction_NUTS_BPM == factor(dat[["Y"]])))

  U_NUTS <- BPM_membership_Normal(X = dat2[["X"]], Lambda = res_NUTS_BPM[["Lambda"]], Mu = res_NUTS_BPM[["Mu"]], a = res_NUTS_BPM[["a"]], rho = res_NUTS_BPM[["rho"]], VI = FALSE, nchain = 1, nskip = 2, seed = 1)
  prediction_NUTS_BPM <- predict(svm_NUTS, U_NUTS)
  acc <- sum(prediction_NUTS_BPM == factor(dat2[["Y"]])) # 100
  print(acc)
  accuracy_BPM <- c(accuracy_BPM, acc)
  estimate_BPM[[i]] <- res_NUTS_BPM
}

```

```{r}
estimate_SPM <- list()
accuracy_SPM <- c() # 65 63 71 99 100 100 100 100 100 100 100 100
for (i in 2:12){
  print(i)
  theta <- pi / 12 * i
  s <- 0.01

  dat <- training_dat_generator(r = 1, theta = theta, s = s, N = 100, seed = seed1) # for training
  dat2 <- training_dat_generator(r = 1, theta = theta, s = s, N = 100, seed = seed2) # for testing
  
  res_VI <- SPM_training_Normal(X = dat[["X"]], Y = dat[["Y"]], Ts = Ts, b = 0.1, alpha = c(1, 1), mu_Mu = mu_Mu, sigma2_Mu = 1, alpha_Lambda = alpha_Lambda, beta_Lambda = 0.1, VI = TRUE, nskip = 2, seed = 1)
  
  prediction_VI <- SPM_predicting_Normal(X = dat2[["X"]], Lambda = res_VI[["Lambda"]], Mu = res_VI[["Mu"]], a = res_VI[["a"]], rho = res_VI[["rho"]], Ts = Ts, nsample = nsample, seed = 1, w = NULL)
  acc <- sum(prediction_VI[["labels"]] == dat2[["Y"]])
  print(acc)
  accuracy_SPM <- c(accuracy_SPM, acc)
  estimate_SPM[[i]] <- res_VI
}

```


#### previous
```{r}
# test gamma prior
nd <-seq(0, 1, by = 0.01)
plot(nd, dgamma(x = nd, shape = 1, rate = 10))
```




```{R}
# test SPM 
res_VI <- SPM_training_Normal(X = dat[["X"]], Y = dat[["Y"]], Ts = Ts, b = 0.1, alpha = c(1, 1), mu_Mu = mu_Mu, sigma2_Mu = sigma2_Mu, alpha_Lambda = alpha_Lambda, beta_Lambda = beta_Lambda, VI = TRUE, nskip = 2, seed = 1)
res_VI[['Mu']]
res_VI

prediction_VI <- SPM_predicting_Normal(dat2[["X"]], res_VI[["Lambda"]], res_VI[["Mu"]], res_VI[["a"]], res_VI[["rho"]], Ts, nsample, seed, w = NULL)
print(sum(prediction_VI[["labels"]] == dat2[["Y"]]))

# test BPM
res_BPM_nuts <- BPM_training_Normal(X = dat[['X']], b = 0.1, alpha = rep(1, 3), mu_Mu = mu_Mu, sigma2_Mu = sigma2_Mu, alpha_Lambda = alpha_Lambda, beta_Lambda = beta_Lambda, ntopic = 3, VI = FALSE, ntrace = 1000, nchain = 2, nskip = 2, seed = 1)
res_BPM_nuts[["Mu"]]
res_BPM_nuts[["U"]]

U_BPM <- BPM_membership_Normal1(X = dat2[["X"]], res_BPM_nuts[["Lambda"]], res_BPM_nuts[["Mu"]], res_BPM_nuts[["a"]], res_BPM_nuts[["rho"]], VI = TRUE, nskip = 2, seed = 1)

u1 <- BPM_membership_Normal1(X = dat[["X"]], dat[["Lambda"]], dat[["Mu"]], 10, rep(1/3,3), VI = TRUE, nskip = 2, seed = 1)
svm_BPM <- svm(factor(dat[["Y"]]) ~ res_BPM_nuts[["U"]])
prediction_BPM <- predict(svm_BPM, U_BPM)
sum(prediction_BPM == factor(dat2[["Y"]]))

paras1 <- get_parameters_Normal(X = dat[["X"]], Lambda = res_BPM_nuts[["Lambda"]], Mu = res_BPM_nuts[["Mu"]], U = res_BPM_nuts[["U"]])
paras2 <- get_parameters_Normal(X = dat[["X"]], Lambda = dat$Lambda, Mu = dat$Mu, U = dat[["U"]])
paras3 <- get_parameters_Normal(X = dat[["X"]], Lambda = dat$Lambda, Mu = dat$Mu, U = u1)
paras1[["MuX"]] - paras2[["MuX"]]
paras3[["MuX"]] - paras2[["MuX"]]

```



```{r}
a1 <- c()
l1 <- list()
for(i in 1:12){
  theta <- pi * i * 1 / 12
  dat <- training_dat_generator(1, theta, 0.1)
  seed <- 1
  res_VI <- SPM_training_Normal(dat[["X"]], dat[["Y"]], Ts, 0.1, c(1, 1), 0, 100, 1, 1, TRUE, nskip = nskip, seed = seed)
  prediction_VI <- SPM_predicting_Normal(dat[["X"]], res_VI[["Lambda"]], res_VI[["Mu"]], res_VI[["a"]], res_VI[["rho"]], Ts, nsample, seed, w = NULL)
  a1 <- c(a1, sum(prediction_VI[["labels"]] == dat[["Y"]]))
  print(sum(prediction_VI[["labels"]] == dat[["Y"]]))
  l1[[i]] <- res_VI
}

a2 <- c()
li2 <- list()
for(i in 1:12){
  theta <- pi * i * 1 / 12
  dat <- training_dat_generator(1, theta, 0.1)
  seed <- 1
  res_BPM_VI <- BPM_training_Normal(dat[['X']], 0.1, rep(1, 3), 0, 50, 2, 5, 3, FALSE, nchain = 1, ntrace = 1000, seed = seed)
  f2 <- svm(factor(dat[["Y"]]) ~ res_BPM_VI[["U"]])
l2 <- predict(f2, res_BPM_VI[["U"]])
print(sum(l2 == factor(dat[["Y"]])))
a2 <- c(a2, sum(l2 == factor(dat[["Y"]])))
li2[[i]] <- res_BPM_VI
}


a2
li2[[1]]$Mu
li2[[3]]$Mu
li2[[6]]$Mu
c(1, 0, r * cos(theta), r * sin(theta), 0, 0)
li2[[12]]$Mu
l1[[6]]$Mu
li2[[6]]$U
```




```{r}
accuracy <- data.frame(theta = rep(pi / 12 * 1:12, 2), accuracy = c(a1, a2), method = rep(c("supervised", "unsupervised"), each = 12))
accuracy %>% ggplot(aes(x = theta, y = accuracy, color = method))  + geom_point()
 

```

